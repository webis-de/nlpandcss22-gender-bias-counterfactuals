{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e53e13ae-8a0c-4d14-9536-c5bc494ce3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# nvidia-smi\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cc5341a-1389-4f6b-9bc2-f9f0e4fba7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from itertools import groupby\n",
    "from names_dataset import NameDataset\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a22a11c-7285-42ea-815e-b34d43a0355c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "962a6877-fe49-421f-8dcc-54a7c72b01e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = \"../data/\"\n",
    "PA_PATH = PREFIX + \"sap2017-connotation-frames-power-agency/\"\n",
    "MS_PATH = PREFIX + \"bamman2013-movie-summaries/MovieSummaries/\"\n",
    "NLP_PATH = MS_PATH + 'corenlp_plot_summaries/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f0399ed-1d2d-4589-a16b-d8389e9b8748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from mov_nlp_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf09b57-0913-4f34-b83f-8ec88192be45",
   "metadata": {},
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530b727f-03ac-4b48-a434-025c2627052e",
   "metadata": {},
   "source": [
    "@inproceedings{bamman-etal-2013-learning,\n",
    "    title = \"Learning Latent Personas of Film Characters\",\n",
    "    author = \"Bamman, David  and\n",
    "      O{'}Connor, Brendan  and\n",
    "      Smith, Noah A.\",\n",
    "    booktitle = \"Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n",
    "    month = aug,\n",
    "    year = \"2013\",\n",
    "    address = \"Sofia, Bulgaria\",\n",
    "    publisher = \"Association for Computational Linguistics\",\n",
    "    url = \"https://aclanthology.org/P13-1035\",\n",
    "    pages = \"352--361\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd89ddf1-c33a-41be-809e-4e7cd7a25b18",
   "metadata": {},
   "source": [
    "Get data at http://www.cs.cmu.edu/~ark/personas/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a6e4fb0-c12b-4678-80d2-54e2ce644f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23890098</th>\n",
       "      <td>Shlykov, a hard-working taxi driver and Lyosha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31186339</th>\n",
       "      <td>The nation of Panem consists of a wealthy Capi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20663735</th>\n",
       "      <td>Poovalli Induchoodan  is sentenced for six yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231378</th>\n",
       "      <td>The Lemon Drop Kid , a New York City swindler,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595909</th>\n",
       "      <td>Seventh-day Adventist Church pastor Michael Ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       text\n",
       "id                                                         \n",
       "23890098  Shlykov, a hard-working taxi driver and Lyosha...\n",
       "31186339  The nation of Panem consists of a wealthy Capi...\n",
       "20663735  Poovalli Induchoodan  is sentenced for six yea...\n",
       "2231378   The Lemon Drop Kid , a New York City swindler,...\n",
       "595909    Seventh-day Adventist Church pastor Michael Ch..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sums = pd.read_csv(MS_PATH + 'plot_summaries.txt', sep='\\t', names=['id', 'text'])\n",
    "sums = sums.set_index('id')\n",
    "sums.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a54d900d-fd43-467b-93c0-80acc84a4ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cha = pd.read_csv(MS_PATH + 'character.metadata.tsv', sep='\\t', names=['id', 'fid', 'date', 'cha_name', 'actor_birth', 'actor_gender', 'actor_height', 'actor_ethnicity', 'actor_name', 'actor_age', 'cha_actor_fid', 'cha_fid', 'actor_fid'])\n",
    "cha = cha.drop(columns=['actor_height', 'actor_ethnicity', 'cha_actor_fid'])\n",
    "cha.index = pd.MultiIndex.from_arrays(cha[['id', 'cha_fid']].values.T, names=['mid', 'cid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49077525-7dbc-4ebe-a956-763193a60f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# character must have a name and gender (TODO: gender name lists?)\n",
    "cha = cha[cha.cha_name.notna() & cha.actor_gender.notna()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78325d50-5258-48c3-a391-90c981d78260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not unique index when multiple actors played one role -> keep only the first\n",
    "cha = cha[~cha.index.duplicated('first')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a37323a5-c534-4c6a-82dc-fb484b4fab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove chars without summary\n",
    "cha = cha[cha['id'].isin(sums.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83951c9d-8932-4485-8957-2e294843936d",
   "metadata": {},
   "source": [
    "## preprocess names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a0f1243-0a35-4441-9092-1008eaf00dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dataset = NameDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d70b0ee-8067-4b85-ab2c-c55c6bf5d1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new colum cha_names\n",
    "cha['cha_names'] = cha['cha_name'].str.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47500781-b0ac-44fa-9ddf-7f59e4f62a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter names with only one letter\n",
    "cha = cha[cha.cha_name.apply(len) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d727802b-98cf-45df-a20e-95a21fd7714f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_firstname(names):\n",
    "    max_score = 0\n",
    "    first_name = ''\n",
    "    for i in range(len(names)):\n",
    "        curr_score = name_dataset.search_first_name(names[i]) \n",
    "        if curr_score > max_score:\n",
    "            max_score = curr_score\n",
    "            first_name = names[i]\n",
    "            \n",
    "    # threshold\n",
    "    if max_score > 0.01:\n",
    "        return first_name\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86fada55-7149-4622-9776-262e91cae92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cha['firstname'] = cha['cha_names'].apply(get_firstname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "868b7c1b-dd57-4e49-ae97-ad8d13a46a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cha = cha[cha.firstname.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11349fc4-528c-4c2e-a0e9-a5cd1f2de153",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove movie summaries without characters\n",
    "sums = sums[sums.index.isin(cha['id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49754ebe-068a-4dd3-a142-8232706bcf5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104371, 21716)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cha), len(sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee762f2-c4a2-4e4b-a812-84285a2af032",
   "metadata": {},
   "source": [
    "# get sentences for characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e77e311e-44fa-40ef-ad2c-e3c6091ce3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ner_persons_per_sentence(mid, sents):    \n",
    "    persons = [] # list with person token list for each sentence\n",
    "    person_tokens = [] # list of lists with subsequent person tokens\n",
    "    for s in sents['sentence']:\n",
    "        person_token = [] # list of subsequent person tokens\n",
    "        try:\n",
    "            for t in s['tokens']['token']:\n",
    "                if isinstance(t, dict) and t['NER'] == 'PERSON': # is person\n",
    "                    person_token.append((t['word'], (s['@id'], t['@id'])))\n",
    "                else:\n",
    "                    if len(person_token) > 0:\n",
    "                        person_tokens.append(person_token)\n",
    "                    person_token = []\n",
    "        except:\n",
    "            pass # parsing error\n",
    "    return person_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ceff089f-a0c0-4e7a-b357-3242368e62ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_character_match(mid, person_tokens):\n",
    "    chars = cha[cha['id'] == mid]\n",
    "    result = []\n",
    "    \n",
    "    for token_list in person_tokens:\n",
    "        cid = None\n",
    "        name = \" \".join([t[0] for t in token_list]) # merge to full name       \n",
    "        if len(chars[chars.cha_name == name]) == 1: # no confusions\n",
    "            # full name found in text\n",
    "            cid = chars[chars.cha_name == name].index.item()[1]\n",
    "\n",
    "        if not cid:\n",
    "            # maybe it is only the first name?            \n",
    "            if len(token_list) == 1:\n",
    "                if len(chars[chars.firstname == name]) == 1: # no confusions\n",
    "                    # first name found in text\n",
    "                    cid = chars[chars.firstname == name].index.item()[1]\n",
    "                                                                      \n",
    "        if cid:\n",
    "            result.append({\n",
    "                'name': name,\n",
    "                'cid': cid,\n",
    "                'st_ids' : [token[1] for token in token_list],\n",
    "            })\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90dd2f75-8756-4054-a21c-c4f1c33aa111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_character(character_matches):    \n",
    "    result = []\n",
    "    character_matches.sort(key=lambda x: x['cid'])\n",
    "    for k, v in groupby(character_matches, key = lambda x: x['cid']):\n",
    "        values = [value for value in list(v)]\n",
    "        result.append({\n",
    "            'cid': k, \n",
    "            'names': list(set([entry['name'] for entry in values])),\n",
    "            'st_ids': [entry['st_ids'] for entry in values]\n",
    "        })\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f1c8785-2824-42bf-acee-ec47927e3be2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def coref_to_st_id_list(coref):\n",
    "    result = []\n",
    "    try:\n",
    "        for i in range(len(coref['coreference'])):\n",
    "            coref_elem = coref['coreference'][i]\n",
    "            coref_group = []\n",
    "\n",
    "            for mention in coref_elem['mention']:\n",
    "                mention_elems = []\n",
    "                for i in range(int(mention['start']), int(mention['end'])): # end is exclusive\n",
    "                    st_id = (mention['sentence'], str(i))\n",
    "                    mention_elems.append(st_id)\n",
    "                coref_group.append(mention_elems)\n",
    "            result.append(coref_group)\n",
    "    except:\n",
    "        pass # parsing error\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afc810ae-b6ec-4124-bab0-2bb03204b86f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_coreferences(mid, character_occurences, coref):\n",
    "    result = []\n",
    "    \n",
    "    for char_occur in character_occurences:\n",
    "        corefs = []\n",
    "        char_st_ids = [item for sublist in char_occur['st_ids'] for item in sublist] # flatten char occur st_ids\n",
    "        coref_st_ids = coref_to_st_id_list(coref) # get corefs as nested st_id lists\n",
    "        \n",
    "        for coref_group in coref_st_ids:\n",
    "            coref_group_flat = [item for sublist in coref_group for item in sublist] # flatten coref_groups \n",
    "            intersection = set(tuple(x) for x in char_st_ids).intersection(set(tuple(x) for x in coref_group_flat))\n",
    "            if len(intersection) > 0 and not coref_group in char_occur['st_ids']:\n",
    "                corefs.append(coref_group)\n",
    "                \n",
    "        char_occur['coref'] = corefs\n",
    "        result.append(char_occur)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eefb7c81-8c18-49f1-a180-4f7e652abc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences_for_characters(characters_w_coreferences, sents):\n",
    "    result = {}\n",
    "    \n",
    "    for character in characters_w_coreferences:\n",
    "        elem = character\n",
    "        sentences = []\n",
    "        sent_ids = []\n",
    "        \n",
    "        # sentences for st_ids\n",
    "        for st_id in character['st_ids']:\n",
    "            sent_id = st_id[0][0]\n",
    "            \n",
    "            if not sent_id in sent_ids:\n",
    "                sent_ids.append(sent_id)\n",
    "                sentences.append((get_sentence(sents, sent_id), st_id)) # only sentence interesting, take s_id from first elem\n",
    "            \n",
    "        \n",
    "        # sentences for corefs\n",
    "        for coref_group in character['coref']:\n",
    "            for mention in coref_group:\n",
    "                sent_id = mention[0][0]\n",
    "                \n",
    "                if not sent_id in sent_ids:\n",
    "                    sent_ids.append(sent_id)\n",
    "                    sentences.append((get_sentence(sents, sent_id), mention)) # only sentence interesting, take s_id from first elem\n",
    "             \n",
    "                \n",
    "        elem['sentences'] = sentences\n",
    "        result[(character['cid'], mid)] = elem\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2eb94c-93d1-431e-9bcd-8031d6730629",
   "metadata": {},
   "source": [
    "# put all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "814ca01c-a1de-460a-8bfe-dc4c6b712cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences_pipeline(mid):\n",
    "    sents, coref = get_nlp_file(mid)\n",
    "    \n",
    "    ner_persons = get_ner_persons_per_sentence(mid, sents)\n",
    "    character_matches = get_best_character_match(mid, ner_persons)\n",
    "    character_occurences = group_by_character(character_matches)\n",
    "    characters_w_coreferences = find_coreferences(mid, character_occurences, coref)\n",
    "    return get_sentences_for_characters(characters_w_coreferences, sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30cd2a21-1098-4a57-a69e-8db635df0f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = 31186339 # (just for development)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c156bf74-794e-4952-83b6-214a6210486a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_sentences_pipeline(mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "452ee328-7d33-4c94-b1dd-476d54e5cc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 21716/21716 [17:59<00:00, 20.11it/s]\n"
     ]
    }
   ],
   "source": [
    "result = {}\n",
    "for mid in tqdm(sums.index, total=len(sums)):\n",
    "    next_result = get_sentences_pipeline(mid)\n",
    "    \n",
    "    key_intersect = result.keys() & next_result.keys() \n",
    "    if (len(key_intersect)) == 0:\n",
    "        result.update(next_result)\n",
    "    else:\n",
    "        print(mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "47cddd14-1a3a-4b04-b5f5-56884a2339ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(result, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4010eac5-c8fb-4454-b287-259758328dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>names</th>\n",
       "      <th>st_ids</th>\n",
       "      <th>coref</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/m/0c01vfc</th>\n",
       "      <th>31186339</th>\n",
       "      <td>/m/0c01vfc</td>\n",
       "      <td>[Katniss]</td>\n",
       "      <td>[[(5, 4)], [(6, 11)], [(12, 17)], [(14, 4)], [...</td>\n",
       "      <td>[[[('39', '17'), ('39', '18'), ('39', '19')], ...</td>\n",
       "      <td>[({'@id': '5', 'tokens': OrderedDict([('token'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/m/0c03gdc</th>\n",
       "      <th>31186339</th>\n",
       "      <td>/m/0c03gdc</td>\n",
       "      <td>[Peeta Mellark, Peeta]</td>\n",
       "      <td>[[(6, 1), (6, 2)], [(7, 3)], [(9, 9)], [(11, 5...</td>\n",
       "      <td>[[[('6', '1'), ('6', '2'), ('6', '3'), ('6', '...</td>\n",
       "      <td>[({'@id': '6', 'tokens': OrderedDict([('token'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/m/0dr_hx_</th>\n",
       "      <th>31186339</th>\n",
       "      <td>/m/0dr_hx_</td>\n",
       "      <td>[Primrose Everdeen]</td>\n",
       "      <td>[[(4, 7), (4, 8)]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[({'@id': '4', 'tokens': OrderedDict([('token'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/m/0gwc3bn</th>\n",
       "      <th>31186339</th>\n",
       "      <td>/m/0gwc3bn</td>\n",
       "      <td>[Caesar Flickerman]</td>\n",
       "      <td>[[(9, 6), (9, 7)]]</td>\n",
       "      <td>[[[('9', '6'), ('9', '7')], [('9', '12')]], [[...</td>\n",
       "      <td>[({'@id': '9', 'tokens': OrderedDict([('token'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/m/0gwc3ck</th>\n",
       "      <th>31186339</th>\n",
       "      <td>/m/0gwc3ck</td>\n",
       "      <td>[Crane]</td>\n",
       "      <td>[[(31, 22)], [(52, 10)]]</td>\n",
       "      <td>[[[('5', '4')], [('6', '11')], [('6', '14')], ...</td>\n",
       "      <td>[({'@id': '31', 'tokens': OrderedDict([('token...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/m/0cwf3b7</th>\n",
       "      <th>17208834</th>\n",
       "      <td>/m/0cwf3b7</td>\n",
       "      <td>[Jules]</td>\n",
       "      <td>[[(6, 11)], [(17, 10)]]</td>\n",
       "      <td>[[[('17', '8'), ('17', '9'), ('17', '10'), ('1...</td>\n",
       "      <td>[({'@id': '6', 'tokens': OrderedDict([('token'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/m/0cwf3b_</th>\n",
       "      <th>17208834</th>\n",
       "      <td>/m/0cwf3b_</td>\n",
       "      <td>[Jensen]</td>\n",
       "      <td>[[(14, 8)], [(15, 3)], [(15, 15)], [(15, 26)],...</td>\n",
       "      <td>[[[('14', '8')], [('15', '3')], [('15', '15')]...</td>\n",
       "      <td>[({'@id': '14', 'tokens': OrderedDict([('token...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/m/0cwf3bm</th>\n",
       "      <th>17208834</th>\n",
       "      <td>/m/0cwf3bm</td>\n",
       "      <td>[Jimmy]</td>\n",
       "      <td>[[(2, 19)], [(3, 5)], [(10, 15)], [(11, 1)], [...</td>\n",
       "      <td>[[[('2', '19'), ('2', '20'), ('2', '21'), ('2'...</td>\n",
       "      <td>[({'@id': '2', 'tokens': OrderedDict([('token'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/m/0cwf3cb</th>\n",
       "      <th>17208834</th>\n",
       "      <td>/m/0cwf3cb</td>\n",
       "      <td>[Steven]</td>\n",
       "      <td>[[(2, 23)], [(6, 13)], [(17, 14)], [(40, 3)], ...</td>\n",
       "      <td>[[[('2', '19'), ('2', '20'), ('2', '21'), ('2'...</td>\n",
       "      <td>[({'@id': '2', 'tokens': OrderedDict([('token'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/m/0cwf3cw</th>\n",
       "      <th>17208834</th>\n",
       "      <td>/m/0cwf3cw</td>\n",
       "      <td>[Kyle]</td>\n",
       "      <td>[[(2, 25)], [(10, 23)], [(11, 3)], [(12, 17)],...</td>\n",
       "      <td>[[[('2', '19'), ('2', '20'), ('2', '21'), ('2'...</td>\n",
       "      <td>[({'@id': '2', 'tokens': OrderedDict([('token'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42277 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            cid                   names  \\\n",
       "/m/0c01vfc 31186339  /m/0c01vfc               [Katniss]   \n",
       "/m/0c03gdc 31186339  /m/0c03gdc  [Peeta Mellark, Peeta]   \n",
       "/m/0dr_hx_ 31186339  /m/0dr_hx_     [Primrose Everdeen]   \n",
       "/m/0gwc3bn 31186339  /m/0gwc3bn     [Caesar Flickerman]   \n",
       "/m/0gwc3ck 31186339  /m/0gwc3ck                 [Crane]   \n",
       "...                         ...                     ...   \n",
       "/m/0cwf3b7 17208834  /m/0cwf3b7                 [Jules]   \n",
       "/m/0cwf3b_ 17208834  /m/0cwf3b_                [Jensen]   \n",
       "/m/0cwf3bm 17208834  /m/0cwf3bm                 [Jimmy]   \n",
       "/m/0cwf3cb 17208834  /m/0cwf3cb                [Steven]   \n",
       "/m/0cwf3cw 17208834  /m/0cwf3cw                  [Kyle]   \n",
       "\n",
       "                                                                st_ids  \\\n",
       "/m/0c01vfc 31186339  [[(5, 4)], [(6, 11)], [(12, 17)], [(14, 4)], [...   \n",
       "/m/0c03gdc 31186339  [[(6, 1), (6, 2)], [(7, 3)], [(9, 9)], [(11, 5...   \n",
       "/m/0dr_hx_ 31186339                                 [[(4, 7), (4, 8)]]   \n",
       "/m/0gwc3bn 31186339                                 [[(9, 6), (9, 7)]]   \n",
       "/m/0gwc3ck 31186339                           [[(31, 22)], [(52, 10)]]   \n",
       "...                                                                ...   \n",
       "/m/0cwf3b7 17208834                            [[(6, 11)], [(17, 10)]]   \n",
       "/m/0cwf3b_ 17208834  [[(14, 8)], [(15, 3)], [(15, 15)], [(15, 26)],...   \n",
       "/m/0cwf3bm 17208834  [[(2, 19)], [(3, 5)], [(10, 15)], [(11, 1)], [...   \n",
       "/m/0cwf3cb 17208834  [[(2, 23)], [(6, 13)], [(17, 14)], [(40, 3)], ...   \n",
       "/m/0cwf3cw 17208834  [[(2, 25)], [(10, 23)], [(11, 3)], [(12, 17)],...   \n",
       "\n",
       "                                                                 coref  \\\n",
       "/m/0c01vfc 31186339  [[[('39', '17'), ('39', '18'), ('39', '19')], ...   \n",
       "/m/0c03gdc 31186339  [[[('6', '1'), ('6', '2'), ('6', '3'), ('6', '...   \n",
       "/m/0dr_hx_ 31186339                                                 []   \n",
       "/m/0gwc3bn 31186339  [[[('9', '6'), ('9', '7')], [('9', '12')]], [[...   \n",
       "/m/0gwc3ck 31186339  [[[('5', '4')], [('6', '11')], [('6', '14')], ...   \n",
       "...                                                                ...   \n",
       "/m/0cwf3b7 17208834  [[[('17', '8'), ('17', '9'), ('17', '10'), ('1...   \n",
       "/m/0cwf3b_ 17208834  [[[('14', '8')], [('15', '3')], [('15', '15')]...   \n",
       "/m/0cwf3bm 17208834  [[[('2', '19'), ('2', '20'), ('2', '21'), ('2'...   \n",
       "/m/0cwf3cb 17208834  [[[('2', '19'), ('2', '20'), ('2', '21'), ('2'...   \n",
       "/m/0cwf3cw 17208834  [[[('2', '19'), ('2', '20'), ('2', '21'), ('2'...   \n",
       "\n",
       "                                                             sentences  \n",
       "/m/0c01vfc 31186339  [({'@id': '5', 'tokens': OrderedDict([('token'...  \n",
       "/m/0c03gdc 31186339  [({'@id': '6', 'tokens': OrderedDict([('token'...  \n",
       "/m/0dr_hx_ 31186339  [({'@id': '4', 'tokens': OrderedDict([('token'...  \n",
       "/m/0gwc3bn 31186339  [({'@id': '9', 'tokens': OrderedDict([('token'...  \n",
       "/m/0gwc3ck 31186339  [({'@id': '31', 'tokens': OrderedDict([('token...  \n",
       "...                                                                ...  \n",
       "/m/0cwf3b7 17208834  [({'@id': '6', 'tokens': OrderedDict([('token'...  \n",
       "/m/0cwf3b_ 17208834  [({'@id': '14', 'tokens': OrderedDict([('token...  \n",
       "/m/0cwf3bm 17208834  [({'@id': '2', 'tokens': OrderedDict([('token'...  \n",
       "/m/0cwf3cb 17208834  [({'@id': '2', 'tokens': OrderedDict([('token'...  \n",
       "/m/0cwf3cw 17208834  [({'@id': '2', 'tokens': OrderedDict([('token'...  \n",
       "\n",
       "[42277 rows x 5 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d3d1c48c-0d02-4865-878c-6a46408ba9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      7068\n",
       "2      5146\n",
       "3      3829\n",
       "4      3143\n",
       "5      2643\n",
       "       ... \n",
       "76        1\n",
       "118       1\n",
       "87        1\n",
       "119       1\n",
       "86        1\n",
       "Name: sentences, Length: 105, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentences.apply(len).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bfebbf14-ef2c-4a1c-81c0-9a86a5e168bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(MS_PATH + 'character_sentences.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
