{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "innocent-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# nvidia-smi\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "characteristic-minutes",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from flair.tokenization import SegtokSentenceSplitter\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "noble-dance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger('flair')\n",
    "logger.setLevel(level=logging.ERROR)\n",
    "fh = logging.StreamHandler()\n",
    "logger.addHandler(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "coordinated-retailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = \"../data/\"\n",
    "PA_PATH = PREFIX + \"sap2017-connotation-frames-power-agency/\"\n",
    "S_PATH = PREFIX + \"kiesel2017-webis-simple-sentences-17/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-endorsement",
   "metadata": {},
   "source": [
    "# read power_agency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "metallic-convenience",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_agency = pd.read_csv(PA_PATH + \"agency_power_prepro.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-twelve",
   "metadata": {},
   "source": [
    "# general tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "raising-guide",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = SegtokSentenceSplitter()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "pos_tagger = SequenceTagger.load(\"upos-fast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-reporter",
   "metadata": {},
   "source": [
    "# get sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919a6c45-117a-41ac-97c0-972b017a6883",
   "metadata": {},
   "source": [
    "@InProceedings{kiesel:2017a,\n",
    "  author =                {Johannes Kiesel and Benno Stein and Stefan Lucks},\n",
    "  booktitle =             {24th Annual Network and Distributed System Security Symposium (NDSS 2017)},\n",
    "  doi =                   {10.14722/ndss.2017.23077},\n",
    "  ids =                   {stein:2017a},\n",
    "  month =                 feb,\n",
    "  numpages =              13,\n",
    "  publisher =             {Association for Computational Linguistics},\n",
    "  site =                  {San Diego, CA, USA},\n",
    "  title =                 {{A Large-scale Analysis of the Mnemonic Password Advice}},\n",
    "  year =                  2017\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b452927-0002-4d9c-a3cb-061ea38215ea",
   "metadata": {},
   "source": [
    "Get data at https://zenodo.org/record/205950#.Yi8qtHrMJhE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "according-variety",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(S_PATH + 'webis-simple-sentences-17-corpus-test.txt', delimiter = \"\\n\", names=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "optional-smith",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This way you covert the best part of the old f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In 2004, the city was awarded European Fortres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Sint Jans Cathedral is one of the most pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It will take years to restore the full church,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The only time the crowd can get a bit rough is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  This way you covert the best part of the old f...\n",
       "1  In 2004, the city was awarded European Fortres...\n",
       "2  The Sint Jans Cathedral is one of the most pro...\n",
       "3  It will take years to restore the full church,...\n",
       "4  The only time the crowd can get a bit rough is..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "suited-titanium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37208441"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "desirable-algeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikisents = pd.read_pickle(PA_PATH + 'power_agency_wikisents.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "impaired-bunny",
   "metadata": {},
   "outputs": [],
   "source": [
    "jokesents = pd.read_pickle(PA_PATH + 'power_agency_jokesents.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "compact-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = jokesents.merge(wikisents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "polar-nickel",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents['sents'] = sents['jsents'] + sents['wsents']\n",
    "sents = sents.drop(['jsents','wsents'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-croatia",
   "metadata": {},
   "source": [
    "# determine missing verbs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-transcription",
   "metadata": {},
   "source": [
    "## filter too long sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ruled-artist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2144.000000\n",
       "mean       29.351446\n",
       "std         5.546669\n",
       "min         0.000000\n",
       "25%        26.142615\n",
       "50%        28.971759\n",
       "75%        32.720113\n",
       "max        80.000000\n",
       "Name: sents, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents.sents.apply(lambda x: sum([len(y) for y in x])/len(x) if len(x) > 0 else 0).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eight-ethics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15879663"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents.sents.apply(lambda x: sum([len(y) for y in x])).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "vietnamese-yahoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_long_sents(row):\n",
    "    return [s for s in row if len(s) <= 50]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "prescription-granny",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2144/2144 [00:00<00:00, 4032.29it/s]\n"
     ]
    }
   ],
   "source": [
    "sents['sents'] = sents.sents.progress_apply(filter_long_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "outstanding-bench",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12423502"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents.sents.apply(lambda x: sum([len(y) for y in x])).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "injured-times",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2144.000000\n",
       "mean      232.080224\n",
       "std       158.137586\n",
       "min         0.000000\n",
       "25%        73.750000\n",
       "50%       237.000000\n",
       "75%       370.250000\n",
       "max       492.000000\n",
       "Name: sents, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents.sents.apply(len).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-newton",
   "metadata": {},
   "source": [
    "## filter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "hungry-robertson",
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_n = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "delayed-accused",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents['missing'] = sents.sents.apply(lambda x: goal_n - len(x) if len(x) < goal_n else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "burning-rotation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165751"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sents['missing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-better",
   "metadata": {},
   "source": [
    "### all test.texts to Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-liver",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[test.text.apply(type) == str] # three were NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-plane",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[test.text.apply(len) >= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-somalia",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-hypothesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['sent'] = test.text.apply(Sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-tucson",
   "metadata": {},
   "source": [
    "### filter by stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "empty-validation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2144/2144 [00:00<00:00, 24544.76it/s]\n"
     ]
    }
   ],
   "source": [
    "sents['stem'] = sents.verb.progress_apply(stemmer.stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "opposed-chorus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb</th>\n",
       "      <th>agency</th>\n",
       "      <th>power</th>\n",
       "      <th>verb_prep</th>\n",
       "      <th>prep</th>\n",
       "      <th>lemma</th>\n",
       "      <th>sents</th>\n",
       "      <th>missing</th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abolishes</td>\n",
       "      <td>agency_pos</td>\n",
       "      <td>power_agent</td>\n",
       "      <td>abolishes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abolish</td>\n",
       "      <td>[(Token: 1 is, Token: 2 the, Token: 3 fact, To...</td>\n",
       "      <td>35</td>\n",
       "      <td>abolish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>accelerates</td>\n",
       "      <td>agency_pos</td>\n",
       "      <td>power_agent</td>\n",
       "      <td>accelerates</td>\n",
       "      <td>NaN</td>\n",
       "      <td>accelerate</td>\n",
       "      <td>[(Token: 1 I, Token: 2 accelerated, Token: 3 t...</td>\n",
       "      <td>26</td>\n",
       "      <td>acceler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>accommodates</td>\n",
       "      <td>agency_pos</td>\n",
       "      <td>power_equal</td>\n",
       "      <td>accommodates</td>\n",
       "      <td>NaN</td>\n",
       "      <td>accommodate</td>\n",
       "      <td>[(Token: 1 Vagina, Token: 2 -, Token: 3 \", Tok...</td>\n",
       "      <td>1</td>\n",
       "      <td>accommod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>aches</td>\n",
       "      <td>agency_neg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aches</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ache</td>\n",
       "      <td>[(Token: 1 He, Token: 2 says, Token: 3 to, Tok...</td>\n",
       "      <td>188</td>\n",
       "      <td>ach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>acquaints</td>\n",
       "      <td>agency_pos</td>\n",
       "      <td>power_agent</td>\n",
       "      <td>acquaints</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acquaint</td>\n",
       "      <td>[(Token: 1 They, Token: 2 get, Token: 3 acquai...</td>\n",
       "      <td>6</td>\n",
       "      <td>acquaint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>yelps</td>\n",
       "      <td>agency_pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yelps</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yelp</td>\n",
       "      <td>[(Token: 1 She, Token: 2 limps, Token: 3 on, T...</td>\n",
       "      <td>210</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>yields</td>\n",
       "      <td>agency_equal</td>\n",
       "      <td>power_agent</td>\n",
       "      <td>yields</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yield</td>\n",
       "      <td>[(Token: 1 After, Token: 2 gathering, Token: 3...</td>\n",
       "      <td>40</td>\n",
       "      <td>yield</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>zaps</td>\n",
       "      <td>agency_pos</td>\n",
       "      <td>power_agent</td>\n",
       "      <td>zaps</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zap</td>\n",
       "      <td>[(Token: 1 I, Token: 2 must, Token: 3 admit, T...</td>\n",
       "      <td>234</td>\n",
       "      <td>zap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142</th>\n",
       "      <td>zips</td>\n",
       "      <td>agency_pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zips</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zip</td>\n",
       "      <td>[(Token: 1 As, Token: 2 the, Token: 3 man, Tok...</td>\n",
       "      <td>146</td>\n",
       "      <td>zip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143</th>\n",
       "      <td>zooms</td>\n",
       "      <td>agency_pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zooms</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zoom</td>\n",
       "      <td>[(Token: 1 He, Token: 2 'd, Token: 3 decided, ...</td>\n",
       "      <td>190</td>\n",
       "      <td>zoom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1164 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              verb        agency        power     verb_prep prep        lemma  \\\n",
       "1        abolishes    agency_pos  power_agent     abolishes  NaN      abolish   \n",
       "4      accelerates    agency_pos  power_agent   accelerates  NaN   accelerate   \n",
       "7     accommodates    agency_pos  power_equal  accommodates  NaN  accommodate   \n",
       "14           aches    agency_neg          NaN         aches  NaN         ache   \n",
       "17       acquaints    agency_pos  power_agent     acquaints  NaN     acquaint   \n",
       "...            ...           ...          ...           ...  ...          ...   \n",
       "2139         yelps    agency_pos          NaN         yelps  NaN         yelp   \n",
       "2140        yields  agency_equal  power_agent        yields  NaN        yield   \n",
       "2141          zaps    agency_pos  power_agent          zaps  NaN          zap   \n",
       "2142          zips    agency_pos          NaN          zips  NaN          zip   \n",
       "2143         zooms    agency_pos          NaN         zooms  NaN         zoom   \n",
       "\n",
       "                                                  sents  missing      stem  \n",
       "1     [(Token: 1 is, Token: 2 the, Token: 3 fact, To...       35   abolish  \n",
       "4     [(Token: 1 I, Token: 2 accelerated, Token: 3 t...       26   acceler  \n",
       "7     [(Token: 1 Vagina, Token: 2 -, Token: 3 \", Tok...        1  accommod  \n",
       "14    [(Token: 1 He, Token: 2 says, Token: 3 to, Tok...      188       ach  \n",
       "17    [(Token: 1 They, Token: 2 get, Token: 3 acquai...        6  acquaint  \n",
       "...                                                 ...      ...       ...  \n",
       "2139  [(Token: 1 She, Token: 2 limps, Token: 3 on, T...      210      yelp  \n",
       "2140  [(Token: 1 After, Token: 2 gathering, Token: 3...       40     yield  \n",
       "2141  [(Token: 1 I, Token: 2 must, Token: 3 admit, T...      234       zap  \n",
       "2142  [(Token: 1 As, Token: 2 the, Token: 3 man, Tok...      146       zip  \n",
       "2143  [(Token: 1 He, Token: 2 'd, Token: 3 decided, ...      190      zoom  \n",
       "\n",
       "[1164 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents[sents.missing > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-maximum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_long_test_sents(row):\n",
    "    if len(row) <= 50:\n",
    "        return row\n",
    "    else:\n",
    "        None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-radius",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['sent'] = test.sent.progress_apply(filter_long_test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "mathematical-roommate",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_stems = set(sents[sents.missing > 0].stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_filter_sentences(sent):\n",
    "    if sent and len(sent)>0:\n",
    "        for token in sent:\n",
    "            for stem in missing_stems:\n",
    "                if stem in token.text:\n",
    "                    return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['candidate'] = test['sent'].progress_apply(pre_filter_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['candidate'] = test['candidate'].apply(lambda x: False if type(x) == float else x) # nan -> False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "classified-wedding",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:30<00:00, 3330.45it/s]\n"
     ]
    }
   ],
   "source": [
    "candidates = test[test['candidate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "falling-brake",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:30<00:00, 3330.45it/s]\n"
     ]
    }
   ],
   "source": [
    "print('# Candidates:', len(candidates))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-dinner",
   "metadata": {},
   "source": [
    "# get sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "sound-baking",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_verbprep = power_agency[power_agency.prep.notna()][['lemma', 'prep']]\n",
    "pa_verbprep = list(pa_verbprep.itertuples(index=False, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "split-italy",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_verblemma = set(power_agency.lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "distinguished-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_webis(sent, col):\n",
    "    if len(sent) > 0:\n",
    "        pos_tagger.predict(sent)\n",
    "        for token in sent:\n",
    "            if token.get_tag('pos').value == 'VERB':\n",
    "                token.add_tag('lemma', lemmatizer.lemmatize(token.text, pos='v'))\n",
    "             \n",
    "        for tid in range(len(sent)):\n",
    "            token = sent[tid]\n",
    "            if token.get_tag('pos').value == 'VERB' and token.get_tag('lemma').value in pa_verblemma:\n",
    "                # verb from pa -> has prep?\n",
    "                if tid+1 < len(sent):\n",
    "                    next_token = sent[tid+1]\n",
    "                    \n",
    "                    if (token.get_tag('lemma').value, next_token.text) in pa_verbprep:\n",
    "                        # has prep\n",
    "                        index = power_agency[(power_agency.lemma == token.get_tag('lemma').value) & (power_agency.prep == next_token.text)].index\n",
    "                    else:\n",
    "                        index = power_agency[(power_agency.lemma == token.get_tag('lemma').value) & (~power_agency.prep.notna())].index\n",
    "                else:\n",
    "                    index = power_agency[(power_agency.lemma == token.get_tag('lemma').value) & (~power_agency.prep.notna())].index\n",
    "                    \n",
    "                # add to power_agency    \n",
    "                if len(index) == 1:\n",
    "                    result = power_agency.loc[index[0], col]\n",
    "                    \n",
    "                    if len(result) < upper_bound:\n",
    "                        result.append(sent)\n",
    "                        power_agency.at[index[0], col] = result\n",
    "                else:\n",
    "                    if len(index) > 1:\n",
    "                        print(sent)\n",
    "                        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sustained-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_bound = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "pointed-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'ssents'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "vulnerable-communication",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_agency[col] = [list() for x in range(len(power_agency.index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-picking",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates['test'] = candidates['sent'].progress_apply(lambda s: preprocess_webis(s, col)) # run by script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "desperate-victorian",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_agency.to_pickle(PA_PATH + 'power_agency_webissents.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
